Running automated Hive queries
==============================

The automated collection of statistics during a task is done through the `run_multiple_queries.py <run_multiple_queries.py>`_ script. It runs a Hive query multiple times, and generates graphs from the statistics collected during the query. 
This script is run using:

.. code:: bash

  ./run_multiple_queries.py <repetition> <hive query> <graph title>

In the example below, the Hive query is to display all the unique names in the address_book table which is in the info database. The query will be repeated 10 times, and the graphs generated will be titled "Utilisation during a DISTINCT Hive query".

.. code:: bash

  ./run_multiple_queries.py 10 "use info; SELECT DISTINCT name FROM address_book" "Utilisation during a DISTINCT Hive query"

Run query and collect statistics
--------------------------------
The script creates a new directory to hold the statistics. The name of the directory is the time the script was called. 
It is in the format: "Year-Month-Day Hour:Minute:Second". For example, 2017-10-11-03:47:08. 

For each repetition of the Hive query, a new subdirectory is created for the statistics during the query. These are named: 000, 001, 002, and so forth.

The script obtains the statistics from the InfluxDB database written to by Gauge. These statistics are:

- bytes_in (Bytes the node is transmitting to the port)
- bytes_out (Bytes the node is receiving from the port)
- packets_in (Number of packets the node is transmitting to the port)
- packets_out (Number of packets the node is receiving from the port)

Each statistic has two CSV files generated from it: indv_port and all_ports. indv_port indicates that the CSV file contains data about each individual port, while all_ports aggregate the data network wide. 

It also obtains node utilisation statistics using `cpu_ram_monitor.py <cpu_ram_monitor.py>`_ and `cpu_ram_monitor_main.py <cpu_ram_monitor_main.py>`_. These statistics are: 

- cpu_percent (CPU utilisation of each node in a percentage format)
- disk_usage (Disk usage of each node in percent)
- virtual_memory (Virtual memory usage of each node in percent)

The timestamps in the all of CSV files are in nanoseconds.

Generate graphs from the data
------------------------------
After the data has been collected and the query has been repeated by the specified amount, graphs are generated from the data. This functionality is from `generate_graphs.py <generate_graphs.py>`_, which can be run independently as:

.. code:: bash

  ./generate_graphs.py <statistics_directory> <graph title>

The generate_graphs.py script requires the directory structure and the CSV filenames to be the same as ones generated by the run_multiple_queries.py script. 

It creates a graph for each type of statistic. It also generates graphs without the master for node utilisation. This is because the master is an outlier since it is both a name node and data node, as well as running the SDN controller. 
